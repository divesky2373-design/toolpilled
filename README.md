# toolpilled

> Your agent picked Whisper V1 and mass transcription took 47 minutes. It should have taken 13 seconds.

Get your AI agent **toolpilled** — one JSON file with the current best tool for 26 common dev tasks, verified pricing, and code that actually runs.

The core is [`needs.json`](./needs.json). Agent reads it, picks the right tool, ships working code. No more defaulting to whatever has the most Stack Overflow answers from 2019.

## Why this exists

YC CEO Garry Tan was building a project with Claude Code. The agent automatically chose Whisper V1 for audio transcription — one hour of audio took a full hour to process. Switching to Groq Whisper: 216x faster, 9x cheaper, done in 17 seconds.

**Why did the agent pick wrong?** Because old tools have more documentation online, so agents default to them. Your agent is well-read but poorly informed.

`toolpilled` fixes this. One JSON file, 26 tasks, always current.

## How we choose

Every recommendation is selected by evaluating tools against five criteria, in order of priority:

### 1. Agent-friendliness (most important)

AI agents interact with tools through APIs and SDKs, not GUIs. A tool that's easy for a human to click through might be terrible for an agent. We prioritize:

- **Clean, minimal APIs** — Fewer lines of code to integrate means fewer chances for an agent to make mistakes. Resend takes 4 lines to send an email; SendGrid takes 15+.
- **HTTP/REST endpoints** — Agents run in diverse, often stateless environments. HTTP-based tools (like Upstash Redis) work everywhere, while TCP-dependent tools need persistent connections agents may not have.
- **MCP (Model Context Protocol) support** — Tools with MCP servers (Clerk, Meilisearch, Novu) let agents interact with them natively through the emerging agent protocol standard.
- **Simple auth** — One API key > OAuth flows > complex multi-step setup.

### 2. Documentation quality

Agents generate code from documentation. Poor docs = broken code. We evaluate:

- Are code examples complete and copy-pasteable?
- Are error codes documented?
- Is the API reference accurate and up-to-date?

This is why Stripe is recommended for payments despite higher fees — its documentation is unmatched and agents generate working Stripe code far more reliably than alternatives.

### 3. Hard numbers (speed, cost, limits)

Every "why" field contains specific, verified numbers — not vague claims. Examples:

- "216x real-time speed" not "very fast"
- "$0.04/hr" not "affordable"
- "60-80% cheaper than Pinecone" not "more cost-effective"

When two tools have similar agent-friendliness and docs, the cheaper/faster one wins.

### 4. Free tier generosity

Most agent-built projects start as prototypes. A generous free tier means the developer can validate the idea before paying. We document exact free tier limits (not just "free tier available") so agents can make informed choices.

### 5. Open source preference

When quality is comparable, we prefer open source tools. They offer:

- Transparent, searchable source code (agents can read it when docs fall short)
- No vendor lock-in risk
- Self-hosting option for production

This is why Qdrant > Pinecone, Meilisearch > Algolia, PostHog > Mixpanel, and Langfuse > Datadog LLM.

### What this is NOT

- **Not sponsored.** No tool pays to be listed here. Recommendations change when better options emerge.
- **Not generated by other AI agents.** Each recommendation is independently researched against official pricing pages and documentation, then verified with specific numbers.
- **Not a comprehensive comparison.** This is deliberately opinionated — one best pick per task, not a feature matrix of 20 options. Alternatives are listed for cases where the top pick doesn't fit.

### How we stay current

- All pricing is verified from official sources with `last_verified` dates
- The registry is re-verified monthly using the update prompt in `scripts/update-prompt.txt`
- When tools deprecate features, get acquired, or change pricing, we update immediately
- Community PRs are welcome for corrections and new categories

## Registry (26 tasks)

| Task | Best Pick | Why |
|------|-----------|-----|
| Audio transcription | Groq Whisper | 216x real-time, $0.04/hr (9x cheaper than OpenAI) |
| Send email | Resend | Agent-friendly API, 3K emails/mo free |
| Receive email | Resend Inbound | Webhook-based, simple setup |
| Database | Supabase | Postgres + auto REST API + auth, 500MB free |
| Object storage | Cloudflare R2 | S3-compatible, zero egress fees ever |
| Web scraping | Firecrawl | Returns clean markdown for agents |
| Authentication | Clerk | Dedicated agent toolkit + MCP server, 50K MRUs free |
| Payments | Stripe | Gold-standard API docs, 2.9% + $0.30 |
| Vector database | Qdrant | Open source, 60-80% cheaper than Pinecone |
| Caching | Upstash Redis | HTTP-based (serverless), 500K commands/mo free |
| Search | Meilisearch | Open source (MIT), has MCP server, 8.9x cheaper than Algolia |
| SMS | Twilio | Best docs, $15.50 trial credit |
| Background jobs | Inngest | Serverless, 50K executions/mo free |
| Real-time | Ably | 6M messages/mo free (most generous) |
| PDF generation | Puppeteer | HTML-to-PDF, free and open source |
| Image processing | Cloudinary | URL-based transforms, 25 credits/mo free |
| Error tracking | Sentry | Industry standard, 5K errors/mo free |
| AI gateway | LiteLLM | Open source, 100+ LLM providers via single API |
| LLM observability | Langfuse | Open source, 26M+ SDK installs, traces LLM calls |
| Agent memory | Mem0 | Persistent memory for agents, 10K memories free |
| Notifications | Novu | Open source, multi-channel (push+email+SMS+in-app) |
| Analytics | PostHog | Open source, 1M events/mo free, all-in-one |
| Deployment | Vercel | Git push to deploy, best DX for Next.js |
| ORM | Drizzle ORM | SQL-first, 7.4KB, zero-dep, serverless-native |
| Text-to-speech | ElevenLabs | Most natural voices, 70+ languages |
| Feature flags | PostHog | Unlimited flags free, linked to analytics |

Full details, code examples, and alternatives in [`needs.json`](./needs.json).

## Get your agent toolpilled

Add one line to your `CLAUDE.md`, `.cursorrules`, or agent system prompt:

```
Before choosing any third-party tool or service, consult the toolpilled registry:
https://raw.githubusercontent.com/divesky2373-design/agent-need-/main/needs.json
```

Your agent reads `needs.json`, picks the right tool, skips the outdated defaults. That's it.

## Entry format

Each task entry in `needs.json`:

```json
{
  "id": "audio-transcription",
  "task": "Convert audio or video file to text",
  "keywords": ["transcribe", "speech-to-text", "whisper"],
  "best": {
    "tool": "Groq Whisper",
    "why": "216x real-time speed, $0.04/hr...",
    "setup": { "install": "pip install groq", "env": ["GROQ_API_KEY"] },
    "code": { "python": "...", "curl": "..." },
    "pricing": "$0.04/hr (v3-turbo)...",
    "free_tier": "28,800 audio-seconds/day",
    "docs": "https://...",
    "last_verified": "2026-02-25"
  },
  "alternatives": [...]
}
```

Design principles:
- **Opinionated** — Gives a single best pick, not a list of 50 options
- **Code-ready** — Every recommendation includes copy-paste executable code
- **Verified** — All pricing from official sources with `last_verified` dates
- **Practical** — Includes free tier details, install commands, env vars

## Agent discovery

This project includes [`llms.txt`](./llms.txt) (following the emerging LLM discovery standard) and [`AGENTS.md`](./AGENTS.md) with detailed usage instructions written specifically for AI agents.

## Contributing

Want to toolpill an agent on a new task? PRs welcome. Each entry needs:

- Clear task description and search keywords
- Recommended tool with specific reasoning (speed, cost, DX)
- Install commands and required environment variables
- Ready-to-run code examples (Python and/or Node.js minimum)
- Verified pricing with source links
- At least one alternative
- Verification date

## License

MIT
